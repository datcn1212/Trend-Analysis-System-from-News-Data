{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38632a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# timestamp = 1683936000\n",
    "timestamp = 1683936000\n",
    "date = datetime.datetime.fromtimestamp(timestamp)\n",
    "\n",
    "print(date)\n",
    "print(int(date.timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633aa56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e this\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc4e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read from HDFS\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Specify the HDFS path to the Parquet file\n",
    "hdfs_path = \"hdfs://localhost:9000/dat/data.parquet\"\n",
    "\n",
    "# Read the Parquet data from HDFS\n",
    "df = spark.read.parquet(hdfs_path)\n",
    "\n",
    "# Perform operations on the DataFrame (e.g., display schema, show data)\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484685bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "                .appName(\"Write to HDFS\") \\\n",
    "                .getOrCreate()\n",
    "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "hdfs_path = \"hdfs://localhost:9000/datcao/data.parquet\"\n",
    "df.write.parquet(hdfs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a87a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = spark.read.parquet(\"hdfs://localhost:9000/datcao/test1.parquet\")\n",
    "dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a38e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_filter = words.filter(lambda x: 's' in x)\n",
    "filtered = words_filter.collect()\n",
    "print(\"Fitered RDD -> %s\" % (filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b190d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f027c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320fd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    {\"a\": 1, \"b\": 2},\n",
    "    {\"a\": 5, \"b\": 4}\n",
    "]\n",
    "\n",
    "df2  = spark.createDataFrame(data2)\n",
    "\n",
    "df3 = df1.union(df2)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2938578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35735dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"save to HDFS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cee763",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = spark.read.json(\"hdfs://localhost:9000/datcao/test1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44593924",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "schema = StructType([\n",
    "                        StructField(\"Topic\", StringType(), nullable=False),\n",
    "                        StructField(\"Date\", StringType(), nullable=True),\n",
    "                        StructField(\"Author\", StringType(), nullable=True),\n",
    "                        StructField(\"Title\", StringType(), nullable=False),\n",
    "                        StructField(\"Href\", StringType(), nullable=False),\n",
    "                        StructField(\"Description\", StringType(), nullable=True),\n",
    "                        StructField(\"Body\", StringType(), nullable=False)\n",
    "                    ])\n",
    "data =[{\"Topic\": \"Thời sự\", \"Date\": \"Thứ sáu, 3/2/2023, 17:31 (GMT+7)\", \"Author\": \"Viết Tuân\", \"Title\": \"Tiếp tục sáp nhập huyện, xã \", \"Href\": \"https://vnexpress.net/tiep-tuc-sap-nhap-huyen-xa-4566487.html\", \"Description\": \"Bộ Chính trị yêu cầu tiếp tục sắp xếp đơn vị hành chính cấp huyện, xã đến năm 2030, trong đó khuyến khích địa phương tự đề xuất sáp nhập phù hợp thực tiễn.\", \"Body\": \"Ngày 30/1, Thường trực Ban Bí thư Võ Văn Thưởng thay mặt Bộ Chính trị ký ban hành kết luận về tiếp tục sắp xếp đơn vị hành chính cấp huyện, xã giai đoạn 2023-2030. Theo đó, đến năm 2025, toàn quốc hoàn thành sáp nhập huyện, xã có dân số và diện tích dưới 70% quy định; huyện diện tích dưới 20%, dân số dưới 200% quy định; xã diện tích dưới 20% và dân số dưới 300% quy định. Năm 2030, toàn quốc hoàn thành sáp nhập huyện, xã còn lại có diện tích và dân số dưới chuẩn; huyện diện tích dưới 30% và dân số dưới 200% quy định; xã diện tích dưới 30% và dân số dưới 300% quy định. Tiêu chuẩn của huyện miền núi, vùng cao là có 80.000 người và diện tích 850 km2 trở lên; huyện đồng bằng từ 450 km2; quận từ 35 km2 với dân số ít nhất 150.000. Quy mô dân số của xã 5.000-8.000 người trở lên, diện tích từ 30 km2. Việc sắp xếp huyện, xã thời gian tới phải phù hợp quy hoạch tỉnh, nông thôn, đô thị; xác định rõ lộ trình, đảm bảo đồng thuận của nhân dân. Các địa phương được khuyến khích chủ động đề xuất sắp xếp đơn vị hành chính tinh gọn, phù hợp thực tiễn, kể cả những nơi đã đảm bảo tiêu chuẩn. Các đơn vị hành chính đã sắp xếp giai đoạn trước; ổn định từ lâu, có vị trí biệt lập, yếu tố đặc thù; đơn vị hành chính nông thôn đã được quy hoạch thành đô thị không bắt buộc sáp nhập, trừ khi địa phương có nhu cầu. Cùng với tiếp tục sáp nhập huyện, xã, Bộ Chính trị yêu cầu cấp ủy đảng, chính quyền tổng kết các vấn đề đã rõ, được thực tiễn chứng minh là đúng để hoàn thiện văn bản quy phạm pháp luật, tổ chức thực hiện hiệu quả trong giai đoạn tới. Bộ Chính trị yêu cầu quy định rõ việc sử dụng và lộ trình sắp xếp cán bộ, công chức, số cấp phó dôi dư sau sáp nhập; định mức phân bổ ngân sách cho huyện, xã sau sáp nhập; thời gian hưởng chế độ, chính sách hỗ trợ đặc thù; hỗ trợ đầu tư xây dựng cơ bản. Đảng đoàn Quốc hội được giao chỉ đạo sửa đổi, bổ sung các văn bản để triển khai chủ trương này. Ban cán sự đảng Chính phủ cần nghiên cứu chính sách phù hợp tạo thuận lợi để địa phương sắp xếp huyện, xã. Giai đoạn 2019-2021, toàn quốc đã sắp xếp 21 đơn vị hành chính cấp huyện và 1.056 đơn vị cấp xã, qua đó giảm được 8 huyện và 561 xã. Việc sắp xếp đơn vị hành chính đã giảm 3.437 cơ quan ở cấp xã và 429 cơ quan cấp huyện; tinh giản 3.595 biên chế cấp xã và 141 biên chế cấp huyện; giảm chi ngân sách giai đoạn 2019-2021 hơn 2.000 tỷ đồng.\"}\n",
    "      ]\n",
    "\n",
    "df1 = spark.createDataFrame(data,schema)\n",
    "\n",
    "# Save DataFrame as JSON to HDFS\n",
    "output_path = \"hdfs://localhost:9000/datcao/test5.parquet\"\n",
    "df1.write.json(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a678e9ad",
   "metadata": {},
   "source": [
    "Chú ý: write.json(hdfs_path) thì spark.read.json()\n",
    "       write.parquet thì read.parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185414c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
